{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822efbd7-9e75-4660-b5d7-ea6aa296f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Spark Session Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV data cleaned successfully.\n",
      "‚úÖ Iceberg namespace 'nessie.spotify' verified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data successfully written to Iceberg table `nessie.spotify.tracks` with partitioning.\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "|          spotify_id|              name|             artists|daily_rank|daily_movement|weekly_movement|country|snapshot_date|popularity|is_explicit|duration_ms|          album_name|album_release_date|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo|release_year|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "|2plbrEY59IikOBgBG...|  Die With A Smile|Lady Gaga, Bruno ...|         1|             1|              0|   NULL|   2025-02-17|        98|      false|     251667|    Die With A Smile|        2024-08-16|        NULL|  NULL|  6|    NULL|   0|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|2CGNAOSuO1MEFCbBR...| luther (with sza)| Kendrick Lamar, SZA|         2|             1|              4|   NULL|   2025-02-17|        90|      false|     177598|                 GNX|        2024-11-21|        NULL|  NULL|  2|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|6AI3ezQ4o3HUoP6Dh...|       Not Like Us|      Kendrick Lamar|         3|          NULL|              8|   NULL|   2025-02-17|        92|       true|     274192|         Not Like Us|        2024-05-04|        NULL|  NULL|  1|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|4wJ5Qq0jBN4ajy7ou...|              APT.|    ROS√â, Bruno Mars|         4|             0|           NULL|   NULL|   2025-02-17|        89|      false|     169917|               rosie|        2024-12-06|        NULL|  NULL|  0|    NULL|   0|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|6dOtVTDdiauQNBQED...|BIRDS OF A FEATHER|       Billie Eilish|         5|             1|           NULL|   NULL|   2025-02-17|        96|      false|     210373|HIT ME HARD AND SOFT|        2024-05-17|        NULL|  NULL|  2|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2025-03-13 07:55:...|1276934299245013979|8958347004770290535|               true|\n",
      "|2025-03-13 07:39:...|8958347004770290535|               NULL|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "|          spotify_id|              name|             artists|daily_rank|daily_movement|weekly_movement|country|snapshot_date|popularity|is_explicit|duration_ms|          album_name|album_release_date|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo|release_year|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "|2plbrEY59IikOBgBG...|  Die With A Smile|Lady Gaga, Bruno ...|         1|             1|              0|   NULL|   2025-02-17|        98|      false|     251667|    Die With A Smile|        2024-08-16|        NULL|  NULL|  6|    NULL|   0|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|2CGNAOSuO1MEFCbBR...| luther (with sza)| Kendrick Lamar, SZA|         2|             1|              4|   NULL|   2025-02-17|        90|      false|     177598|                 GNX|        2024-11-21|        NULL|  NULL|  2|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|6AI3ezQ4o3HUoP6Dh...|       Not Like Us|      Kendrick Lamar|         3|          NULL|              8|   NULL|   2025-02-17|        92|       true|     274192|         Not Like Us|        2024-05-04|        NULL|  NULL|  1|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|4wJ5Qq0jBN4ajy7ou...|              APT.|    ROS√â, Bruno Mars|         4|             0|           NULL|   NULL|   2025-02-17|        89|      false|     169917|               rosie|        2024-12-06|        NULL|  NULL|  0|    NULL|   0|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "|6dOtVTDdiauQNBQED...|BIRDS OF A FEATHER|       Billie Eilish|         5|             1|           NULL|   NULL|   2025-02-17|        96|      false|     210373|HIT ME HARD AND SOFT|        2024-05-17|        NULL|  NULL|  2|    NULL|   1|       NULL|        NULL|            NULL|    NULL|   NULL| NULL|        2000|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "‚úÖ Spark Session Stopped\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, StringType, BooleanType, DoubleType\n",
    "from pyspark.sql.functions import col, regexp_replace, year, lit, when\n",
    "\n",
    "# üõ†Ô∏è CONFIGURATIONS\n",
    "CATALOG_URI = \"http://nessie:19120/api/v1\"\n",
    "WAREHOUSE = \"s3a://warehouse/\"\n",
    "STORAGE_URI = \"http://172.21.0.3:9000\"\n",
    "CSV_PATH = \"/workspace/seed-data/Top_spotify_songs.csv\"\n",
    "\n",
    "# üî• Initialize Spark\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName(\"spotify_data_app\")\n",
    "    .setMaster(\"local[*]\")  # Runs locally with all available cores\n",
    "        # Enable logging for Spark History Server\n",
    "        .set(\"spark.eventLog.enabled\", \"true\")\n",
    "        .set(\"spark.eventLog.dir\", \"file:///tmp/spark-events\")\n",
    "        .set(\"spark.history.fs.logDirectory\", \"file:///tmp/spark-events\")\n",
    "        # Include necessary packages\n",
    "        .set(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.3,\"\n",
    "                                     \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,\"\n",
    "                                     \"org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,\"\n",
    "                                     \"software.amazon.awssdk:bundle:2.24.8,\"\n",
    "                                     \"software.amazon.awssdk:url-connection-client:2.24.8\")\n",
    "        # Enable Iceberg and Nessie extensions\n",
    "        .set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,\"\n",
    "                                      \"org.projectnessie.spark.extensions.NessieSparkSessionExtensions\")\n",
    "        # Configure Nessie catalog\n",
    "        .set(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .set(\"spark.sql.catalog.nessie.uri\", CATALOG_URI)\n",
    "        .set(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "        .set(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "        .set(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "        # Set Minio as the S3 endpoint for Iceberg storage\n",
    "        .set(\"spark.sql.catalog.nessie.s3.endpoint\", STORAGE_URI)\n",
    "        .set(\"spark.sql.catalog.nessie.warehouse\", WAREHOUSE)\n",
    "        .set(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"üöÄ Spark Session Started\")\n",
    "\n",
    "# üì• **STEP 1: READ & CLEAN CSV DATA**\n",
    "df = spark.read.option(\"header\", True).csv(CSV_PATH)\n",
    "\n",
    "# ‚úÖ Remove quotes from column values & names\n",
    "df = df.select([regexp_replace(col(c), '\"', '').alias(c) for c in df.columns])\n",
    "df = df.toDF(*[col_name.strip('\"') for col_name in df.columns])\n",
    "\n",
    "# ‚úÖ Convert necessary columns safely\n",
    "def safe_cast(df, col_name, dtype):\n",
    "    return df.withColumn(col_name, when(col(col_name).rlike(\"^[0-9]+$\"), col(col_name).cast(dtype)).otherwise(None))\n",
    "\n",
    "numeric_cols = [\"duration_ms\", \"popularity\", \"daily_rank\", \"daily_movement\", \"weekly_movement\", \"key\", \"mode\"]\n",
    "for col_name in numeric_cols:\n",
    "    df = safe_cast(df, col_name, IntegerType())\n",
    "\n",
    "double_cols = [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]\n",
    "for col_name in double_cols:\n",
    "    df = safe_cast(df, col_name, DoubleType())\n",
    "\n",
    "df = df.withColumn(\"is_explicit\", col(\"is_explicit\").cast(BooleanType()))\n",
    "df = df.withColumn(\"release_year\", year(col(\"release_date\"))) if \"release_date\" in df.columns else df.withColumn(\"release_year\", lit(2000))\n",
    "\n",
    "print(\"‚úÖ CSV data cleaned successfully.\")\n",
    "\n",
    "# üèóÔ∏è **STEP 2: CREATE ICEBERG NAMESPACE**\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.spotify\")\n",
    "print(\"‚úÖ Iceberg namespace 'nessie.spotify' verified.\")\n",
    "\n",
    "# üîç **STEP 3: CHECK & CREATE ICEBERG TABLE WITH PARTITIONING**\n",
    "table_exists = spark.sql(\"SHOW TABLES IN nessie.spotify\").collect()\n",
    "if not any(row[\"tableName\"].lower() == \"tracks\" for row in table_exists):\n",
    "    spark.sql(\"\"\"\n",
    "        CREATE TABLE nessie.spotify.tracks (\n",
    "            spotify_id STRING,\n",
    "            name STRING,\n",
    "            artists STRING,\n",
    "            daily_rank INT,\n",
    "            daily_movement INT,\n",
    "            weekly_movement INT,\n",
    "            country STRING,\n",
    "            snapshot_date STRING,\n",
    "            popularity INT,\n",
    "            is_explicit BOOLEAN,\n",
    "            duration_ms INT,\n",
    "            album_name STRING,\n",
    "            album_release_date STRING,\n",
    "            danceability DOUBLE,\n",
    "            energy DOUBLE,\n",
    "            key INT,\n",
    "            loudness DOUBLE,\n",
    "            mode INT,\n",
    "            speechiness DOUBLE,\n",
    "            acousticness DOUBLE,\n",
    "            instrumentalness DOUBLE,\n",
    "            liveness DOUBLE,\n",
    "            valence DOUBLE,\n",
    "            tempo DOUBLE,\n",
    "            release_year INT\n",
    "        ) USING iceberg\n",
    "        PARTITIONED BY (release_year)\n",
    "        LOCATION 's3a://warehouse/nessie/spotify/tracks';\n",
    "    \"\"\")\n",
    "    print(\"‚úÖ Iceberg table `nessie.spotify.tracks` created with partitioning.\")\n",
    "\n",
    "# üèóÔ∏è **STEP 4: CLEAN DATA & WRITE TO ICEBERG WITH PARTITIONING**\n",
    "expected_columns = [\n",
    "    \"spotify_id\", \"name\", \"artists\", \"daily_rank\", \"daily_movement\", \"weekly_movement\",\n",
    "    \"country\", \"snapshot_date\", \"popularity\", \"is_explicit\", \"duration_ms\",\n",
    "    \"album_name\", \"album_release_date\", \"danceability\", \"energy\", \"key\",\n",
    "    \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\",\n",
    "    \"liveness\", \"valence\", \"tempo\", \"release_year\"\n",
    "]\n",
    "df = df.select(*expected_columns)\n",
    "\n",
    "# **Write data to MinIO with partitioning**\n",
    "df.write.format(\"iceberg\").mode(\"overwrite\").partitionBy(\"release_year\").save(\"nessie.spotify.tracks\")\n",
    "print(\"‚úÖ Data successfully written to Iceberg table `nessie.spotify.tracks` with partitioning.\")\n",
    "\n",
    "# üßê **STEP 5: VERIFY WRITTEN DATA**\n",
    "df_read = spark.read.format(\"iceberg\").load(\"nessie.spotify.tracks\")\n",
    "df_read.show(5)\n",
    "\n",
    "# üìå **STEP 6: CHECK TABLE HISTORY**\n",
    "snapshots = spark.sql(\"SELECT * FROM nessie.spotify.tracks.history ORDER BY made_current_at DESC\")\n",
    "snapshots.show()\n",
    "\n",
    "# üïí **STEP 7: TIME TRAVEL QUERY**\n",
    "latest_snapshot = snapshots.collect()[0][\"snapshot_id\"]\n",
    "df_time_travel = spark.read.format(\"iceberg\").option(\"snapshot-id\", latest_snapshot).load(\"nessie.spotify.tracks\")\n",
    "df_time_travel.show(5)\n",
    "\n",
    "# üõë **STEP 8: STOP SPARK SESSION**\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark Session Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f99ba-0575-4968-ae7a-f2d0f774055b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ae558-823b-486d-97ff-2e3897e70ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb72e9-89db-4a6f-b01b-399a4d28ab5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
